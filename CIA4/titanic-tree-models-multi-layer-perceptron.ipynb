{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import packages and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "",
    "_uuid": ""
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "gender_submission = pd.read_csv(\"/kaggle/input/titanic/gender_submission.csv\")\n",
    "test = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n",
    "train = pd.read_csv(\"/kaggle/input/titanic/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set dimension: (891, 12)\n",
      "Testing set dimension: (418, 11)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set dimension: {train.shape}\")\n",
    "print(f\"Testing set dimension: {test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Functions and classes built for implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The followings are the functions and classes that are used to preprocess and train the data.\n",
    "- `FullNA` function fills NA values of categorical values as \"Missing\", numberical as the median. For `Cabin` column, the first letter was extracted as a variable.\n",
    "- `Title` function extracts 'Mr', 'Miss', and 'Mrs' titles from the passenger names.\n",
    "- `Decoder` function uses one-hot-encoder on categorical variables to create dummy variables. \n",
    "- `SelectCol` function selects certain columns from the dataset and splits the data into training and testing data\n",
    "- `GSCV` function trains `GridSearchCV` on the trainin data and predicts labels for the testing data and saves the result to the output folder.\n",
    "- `Ensemble Propensity` function ensembles the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fill na and set index: FillSet\n",
      "Title function: Title\n",
      "One hot decoder imported: Decoder\n",
      "Select imported: SelectCol\n",
      "Grid Search train: GSCV\n",
      "Ensemble function: EnsemblePropensity\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "print(\"Fill na and set index: FillSet\")\n",
    "def FillNA(X, ind, cat, num, col='Cabin'):\n",
    "\n",
    "    X = X.set_index(ind)\n",
    "    X[cat] = X[cat].fillna('Missing')\n",
    "    X[num] = X[num].fillna(X[num].median())\n",
    "    X[col] = X[col].apply(lambda x: x[0])\n",
    "\n",
    "    return X\n",
    "\n",
    "print(\"Title function: Title\")\n",
    "def Title(df, col):\n",
    "    title = []\n",
    "    for i in df[col]:\n",
    "        if 'Miss.' in i:\n",
    "            title.append('Miss')\n",
    "        elif 'Mrs.' in i:\n",
    "            title.append('Mrs')\n",
    "        elif 'Mr.' in i:\n",
    "            title.append('Mr')\n",
    "        else:\n",
    "            title.append('No')\n",
    "\n",
    "    df[col] = title\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "print(\"One hot decoder imported: Decoder\")\n",
    "class Decoder(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, columns):\n",
    "        super().__init__()\n",
    "\n",
    "        self.columns = columns\n",
    "        self.onehot = OneHotEncoder(drop='first')\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        one = self.onehot.fit_transform(X[self.columns]).toarray()\n",
    "        col_names = self.onehot.get_feature_names()\n",
    "\n",
    "        return pd.concat([X.drop(self.columns, axis=1), pd.DataFrame(one, index=X.index, columns=col_names)], axis=1)\n",
    "\n",
    "\n",
    "print(\"Select imported: SelectCol\")\n",
    "def SelectCol(X, drop_cols, target, col_str):\n",
    "    if col_str is not None:\n",
    "        for i in col_str:\n",
    "            X.apply(lambda i: str(i))\n",
    "\n",
    "    X = X.drop(drop_cols, axis=1)\n",
    "\n",
    "    train = X[~X.Survived.isna()]\n",
    "    test = X[X.Survived.isna()]\n",
    "\n",
    "    return train.drop(target, axis=1), train[target], test.drop(target, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Grid Search train: GSCV\")\n",
    "def GSCV(pipe, params, X, y, test, submission, m, scoring, cv=5):\n",
    "    grid = GridSearchCV(estimator=pipe,\n",
    "                        param_grid=params,\n",
    "                        cv=cv,\n",
    "                        iid=False,\n",
    "                        return_train_score=False,\n",
    "                        refit=True,\n",
    "                        scoring=scoring\n",
    "                       )\n",
    "    grid.fit(X, y)\n",
    "    pd.DataFrame(grid.predict(test), index=submission.index, columns=['Survived']).to_csv(\"/kaggle/working/\" + m + \"_submission.csv\")\n",
    "    return grid.best_score_, grid.best_params_, grid.best_estimator_.predict(test)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Ensemble function: EnsemblePropensity\")\n",
    "def EnsemblePropensity(directory, folder):\n",
    "    d = directory + folder\n",
    "    count = 0\n",
    "    df = pd.DataFrame()\n",
    "    for i in os.listdir(d):\n",
    "        if 'csv' in i:\n",
    "            score = pd.read_csv(d + i)\n",
    "            df = pd.concat([df, score.iloc[:, 1]], axis=1)\n",
    "            count += 1\n",
    "            index = score.iloc[:, 0]\n",
    "\n",
    "    df = pd.DataFrame(np.sum(df, axis=1), columns=['Probability'])\n",
    "    df['Survived'] = [1 if i >= 2 else 0 for i in df.Probability]\n",
    "    df = df.iloc[:, 1]\n",
    "    df.to_csv(d + \"Ensemble_\" + str(count) + \".csv\")\n",
    "\n",
    "    print(\"Ensemble complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepocessing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to process the data, the train and test datasets were combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dim: (891, 12), Test dim: (418, 12)\n",
      "DF dimension: (1309, 12)\n"
     ]
    }
   ],
   "source": [
    "test.insert(test.shape[1], \"Survived\", [np.nan]*len(test))\n",
    "print(f\"Train dim: {train.shape}, Test dim: {test.shape}\")\n",
    "\n",
    "df = pd.concat([train, test], sort=True)\n",
    "print(f\"DF dimension: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[](http://)Filling NA or missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<< Original dataset >>>>>>\n",
      "Missing: Age             263\n",
      "Cabin          1014\n",
      "Embarked          2\n",
      "Fare              1\n",
      "Name              0\n",
      "Parch             0\n",
      "PassengerId       0\n",
      "Pclass            0\n",
      "Sex               0\n",
      "SibSp             0\n",
      "Survived        418\n",
      "Ticket            0\n",
      "dtype: int64\n",
      "<<<<< Filled NA >>>>>>\n",
      "Missing: Age           0\n",
      "Cabin         0\n",
      "Embarked      0\n",
      "Fare          0\n",
      "Name          0\n",
      "Parch         0\n",
      "Pclass        0\n",
      "Sex           0\n",
      "SibSp         0\n",
      "Survived    418\n",
      "Ticket        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"<<<<< Original dataset >>>>>>\")\n",
    "print(f\"Missing: {df.isna().sum()}\")\n",
    "df = FillNA(df, 'PassengerId',['Cabin', 'Embarked'], ['Age','Fare'])\n",
    "print(\"<<<<< Filled NA >>>>>>\")\n",
    "print(f\"Missing: {df.isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting titles from the names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.0</td>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38.0</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC 17599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.0</td>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35.0</td>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>373450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age Cabin Embarked     Fare  Name  Parch  Pclass     Sex  SibSp  \\\n",
       "PassengerId                                                                     \n",
       "1            22.0     M        S   7.2500    Mr      0       3    male      1   \n",
       "2            38.0     C        C  71.2833   Mrs      0       1  female      1   \n",
       "3            26.0     M        S   7.9250  Miss      0       3  female      0   \n",
       "4            35.0     C        S  53.1000   Mrs      0       1  female      1   \n",
       "5            35.0     M        S   8.0500    Mr      0       3    male      0   \n",
       "\n",
       "             Survived            Ticket  \n",
       "PassengerId                              \n",
       "1                 0.0         A/5 21171  \n",
       "2                 1.0          PC 17599  \n",
       "3                 1.0  STON/O2. 3101282  \n",
       "4                 1.0            113803  \n",
       "5                 0.0            373450  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = Title(df, 'Name')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling categorical variables and creating dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dimension: (1309, 23)\n"
     ]
    }
   ],
   "source": [
    "df = Decoder(['Cabin', 'Embarked', 'Pclass', 'Sex', 'Name']).fit_transform(df)\n",
    "print(f\"New dimension: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 21), (891,), (418, 21))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y, test_data = SelectCol(df, ['Ticket'], 'Survived', None)\n",
    "X.shape, y.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train and test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set hyperparameters for the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters and estimators are created\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgbm\n",
    "import catboost as cb\n",
    "\n",
    "model = []\n",
    "accuracy = []\n",
    "best_params = []\n",
    "runtime = []\n",
    "scores = []\n",
    "\n",
    "scoring = 'f1_micro'\n",
    "params = [ {'criterion': ['gini','entropy'],\n",
    "            'max_depth':np.arange(1,20).tolist()},\n",
    "          \n",
    "          {'n_estimators': np.arange(5,30).tolist(),\n",
    "            'criterion': ['gini','entropy'],\n",
    "            'max_depth':np.arange(1,10).tolist()},\n",
    "          \n",
    "          {'learning_rate': [0.001, 0.01, 0.03, 0.05, 0.1, 0.2, 0.3],\n",
    "            'n_estimator': np.arange(5,25).tolist(),\n",
    "            'max_depth':np.arange(3,15).tolist(),\n",
    "             'alpha': [1, 2, 3]},\n",
    "          \n",
    "          {'learning_rate': [0.001, 0.01, 0.03, 0.05, 0.1, 0.2, 0.3],\n",
    "            'n_estimator': np.arange(5,25).tolist(),\n",
    "            'num_leaves':np.arange(3,15).tolist(),\n",
    "             'reg_alpha': [0.01, 0.02, 0.03]},\n",
    "           \n",
    "           {'depth': np.arange(5,25).tolist(),\n",
    "             'learning_rate' : [0.01, 0.03, 0.1, 0.15, 0.3],\n",
    "             'l2_leaf_reg': [1,3,4,9],\n",
    "             'iterations': [100]} ]\n",
    "\n",
    "models = [\"dt\", \"rf\", \"xgb\", \"lgbm\", \"cb\"]\n",
    "\n",
    "estimators = [DecisionTreeClassifier(random_state=234),\n",
    "              RandomForestClassifier(random_state=123),\n",
    "              xgb.XGBClassifier(n_jobs=3),\n",
    "              lgbm.LGBMClassifier(objective = 'binary'),\n",
    "              cb.CatBoostClassifier(silent=True)]\n",
    "\n",
    "print(\"Parameters and estimators are created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(models)):\n",
    "#     est = estimators[i]\n",
    "#     param = params[i]\n",
    "#     m = models[i]\n",
    "#     start = datetime.now()\n",
    "    \n",
    "#     score, parm, estimation = GSCV(pipe=est, \n",
    "#                                   params=param, \n",
    "#                                   X=X, \n",
    "#                                   y=y, \n",
    "#                                   test=test_data,\n",
    "#                                   submission=gender_submission,\n",
    "#                                   m = m,\n",
    "#                                   scoring=scoring\n",
    "#                                   )\n",
    "#     end = datetime.now()\n",
    "    \n",
    "#     model.append(m + \"_\" + scoring)\n",
    "#     accuracy.append(score)\n",
    "#     best_params.append(parm)\n",
    "#     runtime.append(end-start)\n",
    "#     scores.append(scoring)\n",
    "    \n",
    "#     print(f\"<<<< Model: {m} >>>>\")\n",
    "#     print(f\"Train score: {score}\")\n",
    "#     print(f\"Best parameters: {parm}\")\n",
    "#     print(f\"Train Runtime: {end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({'model': model,\n",
    "#             'score': accuracy,\n",
    "#             'best parameters': best_params,\n",
    "#             'runtime': runtime,\n",
    "#             'metric': scores})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuned models (GridSearch takes long time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt done\n",
      "Accuracy 0.8451178451178452\n",
      "rf done\n",
      "Accuracy 0.8653198653198653\n",
      "xgb done\n",
      "Accuracy 0.8911335578002245\n",
      "lgbm done\n",
      "Accuracy 0.9057239057239057\n"
     ]
    }
   ],
   "source": [
    "estimators = [DecisionTreeClassifier(random_state=234, criterion='entropy', max_depth=4),\n",
    "              RandomForestClassifier(random_state=123, criterion='entropy', max_depth=6, n_estimators=5),\n",
    "              xgb.XGBClassifier(n_jobs=3, alpha=1, learning_rate=0.03, max_depth=8, n_estimators=5),\n",
    "              lgbm.LGBMClassifier(objective = 'binary', learning_rate=0.1, n_estimator=5, num_leaves=11, reg_alpha=0.01)]\n",
    "\n",
    "models = [\"dt\", \"rf\",\"xgb\",\"lgbm\"]\n",
    "accuracy=[]\n",
    "\n",
    "for i in range(len(estimators)):\n",
    "    est = estimators[i]\n",
    "    \n",
    "    est.fit(X, y)\n",
    "    y_pred = est.predict(X)\n",
    "    \n",
    "    accuracy.append(accuracy_score(y, y_pred))\n",
    "    pd.DataFrame(est.predict(test_data), columns=['Survived']).to_csv(\"/kaggle/working/\" + \"1_\" + models[i] + \"_submission.csv\")\n",
    "    \n",
    "    print(f\"{models[i]} done\")\n",
    "    print(f\"Accuracy {accuracy_score(y, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dt</td>\n",
       "      <td>0.845118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.865320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.891134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lgbm</td>\n",
       "      <td>0.905724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  accuracy\n",
       "0    dt  0.845118\n",
       "1    rf  0.865320\n",
       "2   xgb  0.891134\n",
       "3  lgbm  0.905724"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'model': models,\n",
    "              \"accuracy\":accuracy\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the data to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "X = Variable(torch.from_numpy(X.values))\n",
    "y = Variable(torch.from_numpy(y.values))\n",
    "test_data = Variable(torch.from_numpy(test_data.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tht model: Multi-layer perceptron with 4 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc1): Linear(in_features=21, out_features=12, bias=True)\n",
       "  (fc2): Linear(in_features=12, out_features=6, bias=True)\n",
       "  (fc3): Linear(in_features=6, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.02, inplace=False)\n",
       "  (relu): ReLU()\n",
       "  (logsoftmax): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(21, 12)\n",
    "        self.fc2 = nn.Linear(12, 6)\n",
    "        self.fc3 = nn.Linear(6, 2)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.02)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.dropout(self.relu(self.fc2(x)))\n",
    "        x = self.logsoftmax(self.fc3(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = MLP()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create batch of 33 rows and train on each batch then predict test labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< Epoch: 1 >>> Train loss: 0.686250 Train accuracy: 61.616161\n",
      "<<< Epoch: 2 >>> Train loss: 0.646963 Train accuracy: 61.616161\n",
      "<<< Epoch: 3 >>> Train loss: 0.675586 Train accuracy: 61.616161\n",
      "<<< Epoch: 4 >>> Train loss: 0.658844 Train accuracy: 61.503933\n",
      "<<< Epoch: 5 >>> Train loss: 0.648814 Train accuracy: 61.616169\n",
      "<<< Epoch: 6 >>> Train loss: 0.642693 Train accuracy: 62.738510\n",
      "<<< Epoch: 7 >>> Train loss: 0.645851 Train accuracy: 64.422012\n",
      "<<< Epoch: 8 >>> Train loss: 0.645888 Train accuracy: 66.105507\n",
      "<<< Epoch: 9 >>> Train loss: 0.651440 Train accuracy: 67.452309\n",
      "<<< Epoch: 10 >>> Train loss: 0.668547 Train accuracy: 67.901245\n",
      "<<< Epoch: 11 >>> Train loss: 0.641403 Train accuracy: 67.003380\n",
      "<<< Epoch: 12 >>> Train loss: 0.674828 Train accuracy: 68.013489\n",
      "<<< Epoch: 13 >>> Train loss: 0.638483 Train accuracy: 68.013481\n",
      "<<< Epoch: 14 >>> Train loss: 0.635847 Train accuracy: 68.350182\n",
      "<<< Epoch: 15 >>> Train loss: 0.643265 Train accuracy: 68.462410\n",
      "<<< Epoch: 16 >>> Train loss: 0.634908 Train accuracy: 69.135811\n",
      "<<< Epoch: 17 >>> Train loss: 0.643496 Train accuracy: 67.564545\n",
      "<<< Epoch: 18 >>> Train loss: 0.624738 Train accuracy: 68.911339\n",
      "<<< Epoch: 19 >>> Train loss: 0.627773 Train accuracy: 69.135803\n",
      "<<< Epoch: 20 >>> Train loss: 0.635688 Train accuracy: 68.237946\n",
      "<<< Epoch: 21 >>> Train loss: 0.633039 Train accuracy: 68.125710\n",
      "<<< Epoch: 22 >>> Train loss: 0.637849 Train accuracy: 68.013489\n",
      "<<< Epoch: 23 >>> Train loss: 0.633720 Train accuracy: 68.237946\n",
      "<<< Epoch: 24 >>> Train loss: 0.626397 Train accuracy: 67.789009\n",
      "<<< Epoch: 25 >>> Train loss: 0.631715 Train accuracy: 68.799118\n",
      "<<< Epoch: 26 >>> Train loss: 0.619886 Train accuracy: 68.350182\n",
      "<<< Epoch: 27 >>> Train loss: 0.631501 Train accuracy: 68.574646\n",
      "<<< Epoch: 28 >>> Train loss: 0.646484 Train accuracy: 68.237946\n",
      "<<< Epoch: 29 >>> Train loss: 0.600062 Train accuracy: 67.789009\n",
      "<<< Epoch: 30 >>> Train loss: 0.647997 Train accuracy: 68.462418\n",
      "<<< Epoch: 31 >>> Train loss: 0.609101 Train accuracy: 69.023575\n",
      "<<< Epoch: 32 >>> Train loss: 0.623381 Train accuracy: 68.686882\n",
      "<<< Epoch: 33 >>> Train loss: 0.621689 Train accuracy: 69.248039\n",
      "<<< Epoch: 34 >>> Train loss: 0.626132 Train accuracy: 68.911346\n",
      "<<< Epoch: 35 >>> Train loss: 0.616737 Train accuracy: 68.686882\n",
      "<<< Epoch: 36 >>> Train loss: 0.619478 Train accuracy: 69.248039\n",
      "<<< Epoch: 37 >>> Train loss: 0.622396 Train accuracy: 69.023582\n",
      "<<< Epoch: 38 >>> Train loss: 0.617595 Train accuracy: 68.574654\n",
      "<<< Epoch: 39 >>> Train loss: 0.618379 Train accuracy: 69.472511\n",
      "<<< Epoch: 40 >>> Train loss: 0.624842 Train accuracy: 68.911346\n",
      "<<< Epoch: 41 >>> Train loss: 0.621478 Train accuracy: 69.248055\n",
      "<<< Epoch: 42 >>> Train loss: 0.617203 Train accuracy: 69.023575\n",
      "<<< Epoch: 43 >>> Train loss: 0.618892 Train accuracy: 68.686874\n",
      "<<< Epoch: 44 >>> Train loss: 0.610716 Train accuracy: 69.584755\n",
      "<<< Epoch: 45 >>> Train loss: 0.603981 Train accuracy: 69.809212\n",
      "<<< Epoch: 46 >>> Train loss: 0.603634 Train accuracy: 69.472511\n",
      "<<< Epoch: 47 >>> Train loss: 0.613441 Train accuracy: 69.248039\n",
      "<<< Epoch: 48 >>> Train loss: 0.613625 Train accuracy: 69.921448\n",
      "<<< Epoch: 49 >>> Train loss: 0.612641 Train accuracy: 69.360275\n",
      "<<< Epoch: 50 >>> Train loss: 0.586271 Train accuracy: 69.472511\n",
      "<<< Epoch: 51 >>> Train loss: 0.601080 Train accuracy: 70.033684\n",
      "<<< Epoch: 52 >>> Train loss: 0.614766 Train accuracy: 69.921448\n",
      "<<< Epoch: 53 >>> Train loss: 0.622315 Train accuracy: 68.686882\n",
      "<<< Epoch: 54 >>> Train loss: 0.596636 Train accuracy: 70.145912\n",
      "<<< Epoch: 55 >>> Train loss: 0.593676 Train accuracy: 69.696983\n",
      "<<< Epoch: 56 >>> Train loss: 0.610825 Train accuracy: 69.023575\n",
      "<<< Epoch: 57 >>> Train loss: 0.595076 Train accuracy: 70.033684\n",
      "<<< Epoch: 58 >>> Train loss: 0.598807 Train accuracy: 70.145912\n",
      "<<< Epoch: 59 >>> Train loss: 0.582847 Train accuracy: 70.482605\n",
      "<<< Epoch: 60 >>> Train loss: 0.586378 Train accuracy: 70.482605\n",
      "<<< Epoch: 61 >>> Train loss: 0.614057 Train accuracy: 69.696976\n",
      "<<< Epoch: 62 >>> Train loss: 0.595519 Train accuracy: 71.043777\n",
      "<<< Epoch: 63 >>> Train loss: 0.560753 Train accuracy: 70.819305\n",
      "<<< Epoch: 64 >>> Train loss: 0.589509 Train accuracy: 71.043777\n",
      "<<< Epoch: 65 >>> Train loss: 0.595315 Train accuracy: 71.268250\n",
      "<<< Epoch: 66 >>> Train loss: 0.589992 Train accuracy: 70.594841\n",
      "<<< Epoch: 67 >>> Train loss: 0.590064 Train accuracy: 70.707085\n",
      "<<< Epoch: 68 >>> Train loss: 0.600502 Train accuracy: 71.043785\n",
      "<<< Epoch: 69 >>> Train loss: 0.583726 Train accuracy: 71.941643\n",
      "<<< Epoch: 70 >>> Train loss: 0.577348 Train accuracy: 72.053871\n",
      "<<< Epoch: 71 >>> Train loss: 0.568616 Train accuracy: 71.268250\n",
      "<<< Epoch: 72 >>> Train loss: 0.585269 Train accuracy: 71.492714\n",
      "<<< Epoch: 73 >>> Train loss: 0.580063 Train accuracy: 71.829407\n",
      "<<< Epoch: 74 >>> Train loss: 0.583817 Train accuracy: 72.278351\n",
      "<<< Epoch: 75 >>> Train loss: 0.588810 Train accuracy: 72.278351\n",
      "<<< Epoch: 76 >>> Train loss: 0.585324 Train accuracy: 71.941643\n",
      "<<< Epoch: 77 >>> Train loss: 0.571120 Train accuracy: 72.839516\n",
      "<<< Epoch: 78 >>> Train loss: 0.585058 Train accuracy: 72.053886\n",
      "<<< Epoch: 79 >>> Train loss: 0.581101 Train accuracy: 71.829414\n",
      "<<< Epoch: 80 >>> Train loss: 0.595267 Train accuracy: 72.390587\n",
      "<<< Epoch: 81 >>> Train loss: 0.581739 Train accuracy: 72.951752\n",
      "<<< Epoch: 82 >>> Train loss: 0.584494 Train accuracy: 72.502815\n",
      "<<< Epoch: 83 >>> Train loss: 0.582340 Train accuracy: 72.615044\n",
      "<<< Epoch: 84 >>> Train loss: 0.577834 Train accuracy: 72.615044\n",
      "<<< Epoch: 85 >>> Train loss: 0.581948 Train accuracy: 72.951744\n",
      "<<< Epoch: 86 >>> Train loss: 0.588743 Train accuracy: 72.166107\n",
      "<<< Epoch: 87 >>> Train loss: 0.576911 Train accuracy: 72.390579\n",
      "<<< Epoch: 88 >>> Train loss: 0.587687 Train accuracy: 72.502815\n",
      "<<< Epoch: 89 >>> Train loss: 0.589390 Train accuracy: 72.053886\n",
      "<<< Epoch: 90 >>> Train loss: 0.588044 Train accuracy: 73.176208\n",
      "<<< Epoch: 91 >>> Train loss: 0.592701 Train accuracy: 72.839508\n",
      "<<< Epoch: 92 >>> Train loss: 0.589648 Train accuracy: 72.502808\n",
      "<<< Epoch: 93 >>> Train loss: 0.576213 Train accuracy: 74.298546\n",
      "<<< Epoch: 94 >>> Train loss: 0.590337 Train accuracy: 74.074074\n",
      "<<< Epoch: 95 >>> Train loss: 0.571588 Train accuracy: 73.737373\n",
      "<<< Epoch: 96 >>> Train loss: 0.578897 Train accuracy: 73.737373\n",
      "<<< Epoch: 97 >>> Train loss: 0.578298 Train accuracy: 72.839516\n",
      "<<< Epoch: 98 >>> Train loss: 0.570189 Train accuracy: 73.625153\n",
      "<<< Epoch: 99 >>> Train loss: 0.576648 Train accuracy: 71.941643\n",
      "<<< Epoch: 100 >>> Train loss: 0.571917 Train accuracy: 72.727272\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.NLLLoss()\n",
    "epoch = 100\n",
    "\n",
    "permutation = torch.randperm(X.size()[0])\n",
    "batch_size = 33\n",
    "\n",
    "for e in range(epoch):\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    \n",
    "    for i in range(0,X.size()[0],batch_size):\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch_x, batch_y = X[indices], y[indices]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logps = model(batch_x.float())\n",
    "        loss = criterion(logps, batch_y.long())\n",
    "        train_loss = loss\n",
    "\n",
    "        ps = torch.exp(logps)\n",
    "        top_ps, top_class = ps.topk(1, dim=1)\n",
    "        equals = top_class == batch_y.view(*top_class.shape)\n",
    "\n",
    "        train_accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        with torch.no_grad():\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            logps = model(test_data.float())\n",
    "            ps = torch.exp(logps)\n",
    "            top_ps, top_class = ps.topk(1, dim=1)\n",
    "\n",
    "            pd.DataFrame(np.array(top_class), columns=['Survived']).to_csv(\"/kaggle/working/\" + str((e+1)) + \"_mlp_submission.csv\")\n",
    "\n",
    "            model.train()\n",
    "    \n",
    "    print(\"<<< Epoch: {} >>>\".format(e+1), \"Train loss: {:3f}\".format(train_loss), \"Train accuracy: {:3f}\".format(train_accuracy*100/(len(X)/batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The end of the notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
